{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e110ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # 解析网页，获取数据\n",
    "import re  # 正则表达式，进行文字匹配\n",
    "import urllib.request\n",
    "import urllib.error  # 制定URL，获取网页数据\n",
    "import xlwt  # 进行excel操作\n",
    "import re\n",
    "# urllib有点久了，可以考虑用lxml或者request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、爬虫初识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 什么是爬虫：网络爬虫是按照一定规则，自动抓取互联网信息的程序或者脚本。\n",
    "> + 爬虫可以做什么：可以爬取自己想看的图片，视频等数据。只要你能通过互联网访问的数据都可以爬取。\n",
    "> - 爬虫的本质：模拟浏览器打开网页，获取网页中我们想要的那部分数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、爬虫的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 准备工作：\n",
    "  通过浏览器查看分析目标网页，学习基本编程规范。\n",
    "> + 获取数据：\n",
    "   通过HTTP库，向目标网站发起请求，请求可以包含额外的header等信息，如果服务器能够正常响应，会得到一个Response，便是所要获取的页面内容。\n",
    "> + 解析内容：\n",
    "   得到的内容可能是HTML，json格式，利用页面解析库、正则表达式等进行解析。\n",
    "> - 保存数据：\n",
    "   将解析出来的数据保存。可以保存为文本文件、excel文件等等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 分析页面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 基本框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    baseurl = \"https://movie.douban.com/top250?start=\"\n",
    "    # 1、爬取网页\n",
    "    dataList = getData(baseurl)\n",
    "    # 2、逐一解析数据\n",
    "\n",
    "    # 3、保存数据\n",
    "    savepath = \".\\\\豆瓣电影Top250.xls\"\n",
    "    saveData(savepath)\n",
    "\n",
    "# 爬取网页\n",
    "\n",
    "\n",
    "def getData(baseurl):\n",
    "    dataList = []\n",
    "    html = askURL(url)\n",
    "    return dataList\n",
    "\n",
    "\n",
    "# 得到指定一个url的网页内容\n",
    "def askURL(url):\n",
    "    # 定义头部信息\n",
    "    head = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Mobile Safari/537.36 Edg/96.0.1054.29\"}\n",
    "    # 表示告诉豆瓣服务器，我们是什么类型的机器、浏览器，我们可以得到什么样的数据\n",
    "    req = urllib.request.Request(url, headers=head)\n",
    "    response = urllib.request.urlopen(req)\n",
    "    html = response.read().decode(\"utf-8\")\n",
    "    return html\n",
    "\n",
    "\n",
    "# 保存数据\n",
    "def saveData(savepath):\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":  # 当程序执行时\n",
    "    # 调用主程序\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 爬取网页"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "response = urllib.request.urlopen(\"http://www.baidu.com\")\n",
    "print(response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib.request.urlopen(\"http://httpbin.org/get\")\n",
    "print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"http://httpbin.org/get\"\n",
    "url = \"https://movie.douban.com/top250?start=0\"\n",
    "head = {\"User-Agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Mobile Safari/537.36 Edg/96.0.1054.29\"} #定义头部信息\n",
    "        #表示告诉豆瓣服务器，我们是什么类型的机器、浏览器，我们可以得到什么样的数据\n",
    "req = urllib.request.Request(url,headers=head)\n",
    "response = urllib.request.urlopen(req)\n",
    "#print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 解析数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网页数据解析，就是将爬取出来的html文件中，想要的信息提取出来。按照字符串的构成规则，提取符合规则的字符串，常用两个模块：BeautifulSoup，re。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re：正则表达式，构成或者分解字符串的规则。正则表达式使用单个字符串来描述、匹配一系列符合某个句法规则的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正则表达式：字符串模式（判断字符串是否符合一定的标准）\n",
    "pat = re.compile(\"AA\") #AA是一个正则表达式，用来去验证其它的字符串\n",
    "pat.search(\"CBA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(2, 4), match='AA'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat.search(\"CBAAABC\") #search方法，进行比对查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(2, 4), match='AA'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"AA\",\"CBAAAABC\")#直接查找，前者是规则，后者是查找的对向\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a']\n",
      "['A', 'S', 'D', 'D', 'F']\n",
      "['ASD', 'DF']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(\"a\",\"ASDasdDFas\"))\n",
    "print(re.findall(\"[A-Z]\",\"ASDasdDFas\"))\n",
    "print(re.findall(\"[A-Z]+\",\"ASDasdDFas\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AbcdcAsd'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sub\n",
    "re.sub('a','A','abcdcasd') #在第3个字符串中找到第一个字符串，并将它替换成第二个字符串\n",
    "#建议在正则表达式中，被比较的字符串前面加上r，不用担心转义字符的问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
