{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40578c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何对数据进行预处理，提高数据质量，是数据分析工作中常见而且非常重要的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主要内容："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 数据合并\n",
    "+ 数据清洗\n",
    "+ 数据标准化\n",
    "+ 数据转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、数据合并:\n",
    "横向或者纵向堆叠合并数据、主键合并数据、重叠合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1、堆叠合并：\n",
    "\n",
    "就是简单的把两个表拼在一起，也称为轴向连接、绑定或连接。根据连接轴的方向，分为横向堆叠和纵向堆叠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None.....)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：append方法也可以用于纵向合并两张表。但是append方法实现纵向表堆叠有一个前提条件，那就是两张表的列名需要完全一致。append方法的基本语法如下：\n",
    "pandas.DataFrame.append(self, other, ignore_index=False, verify_integrity=False)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 主键合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过一个或多个键将两个数据集的行连接起来。针对同一个主键存在两张包含不同字段的表，将其根据某几个字段一一对应拼接起来，结果集列数为两个元数据的列数和减去连接键的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主键合并——merge函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pandas.merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, \n",
    "suffixes=('_x', '_y'), copy=True, indicator=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体见pandas数据分析二"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3、重叠合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据分析和处理过程中若出现两份数据的内容几乎一致的情况，但是某些特征在其中一张表上是完整的，而在另外一张表上的数据则是缺失的时候，可以用combine_first方法进行重叠数据合并，其原理如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "pandas.DataFrame.combine_first(other)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df5是：\n",
      "    System  cpu\n",
      "ID            \n",
      "1   win10   i7\n",
      "2   win10   i5\n",
      "3     NaN  NaN\n",
      "4   win10   i7\n",
      "5     NaN  NaN\n",
      "6     NaN  NaN\n",
      "7    win7   i5\n",
      "8    win7   i5\n",
      "9    win8   i3\n",
      "df6是：\n",
      "    System  cpu\n",
      "ID            \n",
      "1     NaN  NaN\n",
      "2     NaN  NaN\n",
      "3    win7   i3\n",
      "4     NaN  NaN\n",
      "5    win8   i7\n",
      "6    win7   i5\n",
      "7     NaN  NaN\n",
      "8     NaN  NaN\n",
      "9     NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# 建立两个字典，除了ID外，别的特征互补\n",
    "dict1 = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'System': ['win10', 'win10', np.nan, 'win10',\n",
    "                    np.nan, np.nan, 'win7', 'win7', 'win8'],\n",
    "         'cpu': ['i7', 'i5', np.nan, 'i7', np.nan, np.nan, 'i5', 'i5', 'i3']}\n",
    "\n",
    "dict2 = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'System': [np.nan, np.nan, 'win7', np.nan,\n",
    "                    'win8', 'win7', np.nan, np.nan, np.nan],\n",
    "         'cpu': [np.nan, np.nan, 'i3', np.nan, 'i7',\n",
    "                 'i5', np.nan, np.nan, np.nan]}\n",
    "# 转换两个字典为DataFrame\n",
    "df5 = pd.DataFrame(dict1)\n",
    "df6 = pd.DataFrame(dict2)\n",
    "df5.set_index(\"ID\", inplace=True)\n",
    "df6.set_index(\"ID\", inplace=True)\n",
    "print('df5是：\\n', df5)\n",
    "print('df6是：\\n', df6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过重叠合并后的数据为：\n",
      "    System cpu\n",
      "ID           \n",
      "1   win10  i7\n",
      "2   win10  i5\n",
      "3    win7  i3\n",
      "4   win10  i7\n",
      "5    win8  i7\n",
      "6    win7  i5\n",
      "7    win7  i5\n",
      "8    win7  i5\n",
      "9    win8  i3\n"
     ]
    }
   ],
   "source": [
    "print('经过重叠合并后的数据为：\\n', df5.combine_first(df6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   数据重复会导致数据的方差变小，数据分布发生较大变化；缺失会导致样本信息减少，不仅增加了数据分析难度，也会导致数据分析的结果产生较大偏差；异常值会产生“伪回归”，也会对数据分析的结果产生较大影响。因此，需要对数据进行检测，查询是否有重复数据，缺失值和异常值，并要对这些数据进行适当处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 重复值的检测和处理\n",
    "+ 缺失值的检测和处理\n",
    "- 异常值的检测和处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1、检测和处理重复值 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）记录重复:例如下面菜品订单详情表中的dlishe_name特征存放了每个订单的彩票，要找出所有已点的菜品，最简单的方法就是利用去重操作去实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法1、利用list代码去重\n",
    "def delRep(list1):\n",
    "    list2 = []\n",
    "    for i in list1:\n",
    "        if i not in list2:\n",
    "            list2.append(i)\n",
    "    return list2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用\n",
    "dishes = list(detail['dishes_name'])\n",
    "print('去重前的菜品总数为：', len(dishes))\n",
    "dish = delRep(dishes)\n",
    "print('去重后的菜品总数为：', len(dish))\n",
    "print(dish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法2：利用集合set的无重复性去重\n",
    "print('去重前的菜品总数为：', len(dishes))\n",
    "dish_set = set(dishes)\n",
    "print('去重后的菜品总数为：', len(dish_set))\n",
    "print(dish_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 方法3 drop_duplicates函数\n",
    "调用方法：\n",
    "```python \n",
    "pandas.DataFrame(Series).drop_duplicates(self,\n",
    "subset=None,keep='first',inplace=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去重后的菜品总数为： 145\n",
      "detail_id\n",
      "2956          蒜蓉生蚝\n",
      "2958         蒙古烤羊腿\n",
      "2961          大蒜苋菜\n",
      "2966         芝麻烤紫菜\n",
      "2968           蒜香包\n",
      "           ...    \n",
      "7064        海带结豆腐汤\n",
      "4683          冰镇花螺\n",
      "4115         冬瓜炒苦瓜\n",
      "7168       超人气广式肠粉\n",
      "858     百里香奶油烤紅酒牛肉\n",
      "Name: dishes_name, Length: 145, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dish_name = detail['dishes_name'].drop_duplicates()\n",
    "print('去重后的菜品总数为：', len(dish_name))\n",
    "print(dish_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)特征重复：对于连续特征，如果两连续特征的相似度为1，则认为两特征重复，可以去掉一个。相似度可以用相关系数corr来度量。例如菜品订单数据中的销量和售价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销量和售价的kendall相似度为：\n",
      "            counts   amounts\n",
      "counts   1.000000 -0.229968\n",
      "amounts -0.229968  1.000000\n"
     ]
    }
   ],
   "source": [
    "# 求取销量和售价的相似度\n",
    "corrDet = detail[['counts', 'amounts']].corr(method='kendall')\n",
    "print('销量和售价的kendall相似度为：\\n', corrDet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用DataFrame.equal函数去重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2、缺失值的检测和处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)缺失值检测：isnull和notnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的数目为：\n",
      " order_id                 0\n",
      "dishes_id                0\n",
      "logicprn_name        10037\n",
      "parent_class_name    10037\n",
      "dishes_name              0\n",
      "itemis_add               0\n",
      "counts                   0\n",
      "amounts                  0\n",
      "cost                 10037\n",
      "place_order_time         0\n",
      "discount_amt         10037\n",
      "discount_reason      10037\n",
      "kick_back            10037\n",
      "add_inprice              0\n",
      "add_info             10037\n",
      "bar_code             10037\n",
      "picture_file             0\n",
      "emp_id                   0\n",
      "dtype: int64\n",
      "detail每个特征非缺失的数目为：\n",
      " order_id             10037\n",
      "dishes_id            10037\n",
      "logicprn_name            0\n",
      "parent_class_name        0\n",
      "dishes_name          10037\n",
      "itemis_add           10037\n",
      "counts               10037\n",
      "amounts              10037\n",
      "cost                     0\n",
      "place_order_time     10037\n",
      "discount_amt             0\n",
      "discount_reason          0\n",
      "kick_back                0\n",
      "add_inprice          10037\n",
      "add_info                 0\n",
      "bar_code                 0\n",
      "picture_file         10037\n",
      "emp_id               10037\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 代码 5-17\n",
    "print('detail每个特征缺失的数目为：\\n', detail.isnull().sum())\n",
    "print('detail每个特征非缺失的数目为：\\n', detail.notnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)缺失值处理：删除法、替换法和插值法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a）删除法：dropna(),删除观察记录和删除特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除缺失的列前detail的形状为： (10037, 18)\n",
      "去除缺失的列后detail的形状为： (10037, 10)\n"
     ]
    }
   ],
   "source": [
    "print('去除缺失的列前detail的形状为：', detail.shape)\n",
    "print('去除缺失的列后detail的形状为：',\n",
    "      detail.dropna(axis=1, how='any').shape)  # axis=0表示删除有缺失的行，axis=1表示删除有\n",
    "# 缺失的列。how=any表示只要有缺失，就删除。how=all表示只有全部是缺失时才删除。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.DataFrame.dropna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)替换法：用某个特定的值来替换缺失值：fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.DataFrame.fillna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detail每个特征缺失的数目为：\n",
      " order_id             0\n",
      "dishes_id            0\n",
      "logicprn_name        0\n",
      "parent_class_name    0\n",
      "dishes_name          0\n",
      "itemis_add           0\n",
      "counts               0\n",
      "amounts              0\n",
      "cost                 0\n",
      "place_order_time     0\n",
      "discount_amt         0\n",
      "discount_reason      0\n",
      "kick_back            0\n",
      "add_inprice          0\n",
      "add_info             0\n",
      "bar_code             0\n",
      "picture_file         0\n",
      "emp_id               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "detail = detail.fillna(-99)\n",
    "print('detail每个特征缺失的数目为：\\n', detail.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)插值法：线性插值，多项式插值，样条插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6、7时，使用线性插值y1为： [ 76. 102.]\n",
      "当x为6、7时，使用线性插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "# 线性插值\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "x = np.array([1, 2, 3, 4, 5, 8, 9, 10])  # 创建自变量x\n",
    "y1 = np.array([2, 8, 18, 32, 50, 128, 162, 200])  # 创建因变量y1\n",
    "y2 = np.array([3, 5, 7, 9, 11, 17, 19, 21])  # 创建因变量y2\n",
    "LinearInsValue1 = interp1d(x, y1, kind='linear')  # 线性插值拟合x,y1\n",
    "LinearInsValue2 = interp1d(x, y2, kind='linear')  # 线性插值拟合x,y2\n",
    "print('当x为6、7时，使用线性插值y1为：', LinearInsValue1([6, 7]))\n",
    "print('当x为6、7时，使用线性插值y2为：', LinearInsValue2([6, 7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当x为6,7时，使用拉格朗日插值y1为： [72. 98.]\n",
      "当x为6,7时，使用拉格朗日插值y2为： [13. 15.]\n"
     ]
    }
   ],
   "source": [
    "# 拉格朗日插值\n",
    "from scipy.interpolate import lagrange\n",
    "LargeInsValue1 = lagrange(x, y1)  # 拉格朗日插值拟合x,y1\n",
    "LargeInsValue2 = lagrange(x, y2)  # 拉格朗日插值拟合x,y2\n",
    "print('当x为6,7时，使用拉格朗日插值y1为：', LargeInsValue1([6, 7]))\n",
    "print('当x为6,7时，使用拉格朗日插值y2为：', LargeInsValue2([6, 7]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3、异常值检测和处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异常值：数据中个别值的数值明显偏离其余的数值，也叫离群点。异常值的检测主要有3 $\\theta$ 原则和箱线图分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用拉依达准则判定异常值个数为: 209\n",
      "异常值的最大值为： 10\n",
      "异常值的最小值为： 3\n"
     ]
    }
   ],
   "source": [
    "# 定义$3\\theta$准则识别异常值函数\n",
    "def outRange(Ser1):\n",
    "    boolInd = (Ser1.mean()-3*Ser1.std() > Ser1) | \\\n",
    "        (Ser1.mean()+3*Ser1.var() < Ser1)\n",
    "    index = np.arange(Ser1.shape[0])[boolInd]\n",
    "    outrange = Ser1.iloc[index]\n",
    "    return outrange\n",
    "\n",
    "\n",
    "outlier = outRange(detail['counts'])\n",
    "print('使用拉依达准则判定异常值个数为:', outlier.shape[0])\n",
    "print('异常值的最大值为：', outlier.max())\n",
    "print('异常值的最小值为：', outlier.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "销售量数据异常值个数为： 516\n",
      "销售量数据异常值的最大值为： 10\n",
      "销售量数据异常值的最小值为： 2\n"
     ]
    }
   ],
   "source": [
    "# 箱线图分析\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 8))\n",
    "p = plt.boxplot(detail['counts'].values, notch=True)  # 画出箱线图\n",
    "outlier1 = p['fliers'][0].get_ydata()  # fliers为异常值的标签\n",
    "plt.savefig('C:/Users/thsm9/Desktop/菜品异常数据识别.png')\n",
    "plt.show()\n",
    "print('销售量数据异常值个数为：', len(outlier1))\n",
    "print('销售量数据异常值的最大值为：', max(outlier1))\n",
    "print('销售量数据异常值的最小值为：', min(outlier1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38565e2d",
   "metadata": {},
   "source": [
    "#### 3、标准化数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 离差标准化数据\n",
    "+ 标准差标准化数据\n",
    "- 小数定标标准化数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "离差标准化数据：$X^*= \\frac{X-min}{max-min}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离差标准化之前销量和售价数据为：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956            1       49\n",
      "2958            1       48\n",
      "2961            1       30\n",
      "2966            1       25\n",
      "2968            1       13\n",
      "离差标准化之后销量和售价数据为：\n",
      "            counts   amounts\n",
      "detail_id                  \n",
      "2956          0.0  0.271186\n",
      "2958          0.0  0.265537\n",
      "2961          0.0  0.163842\n",
      "2966          0.0  0.135593\n",
      "2968          0.0  0.067797\n"
     ]
    }
   ],
   "source": [
    "# 自定义离差标准化函数\n",
    "def MinMaxScale(data):\n",
    "    data = (data-data.min())/(data.max()-data.min())\n",
    "    return data\n",
    "\n",
    "\n",
    "# 对菜品订单表售价和销量做离差标准化\n",
    "data1 = MinMaxScale(detail['counts'])\n",
    "data2 = MinMaxScale(detail['amounts'])\n",
    "data3 = pd.concat([data1, data2], axis=1)\n",
    "print('离差标准化之前销量和售价数据为：\\n',\n",
    "      detail[['counts', 'amounts']].head())\n",
    "print('离差标准化之后销量和售价数据为：\\n', data3.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准差标准化数据：$X^*= \\frac{X-\\bar{X}}{\\delta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准差标准化之前销量和售价数据为：\n",
      "            counts  amounts\n",
      "detail_id                 \n",
      "2956            1       49\n",
      "2958            1       48\n",
      "2961            1       30\n",
      "2966            1       25\n",
      "2968            1       13\n",
      "标准差标准化之后销量和售价数据为：\n",
      "              counts   amounts\n",
      "detail_id                    \n",
      "2956      -0.177571  0.116671\n",
      "2958      -0.177571  0.088751\n",
      "2961      -0.177571 -0.413826\n",
      "2966      -0.177571 -0.553431\n",
      "2968      -0.177571 -0.888482\n"
     ]
    }
   ],
   "source": [
    "# 自定义标准差标准化函数\n",
    "def StandardScaler(data):\n",
    "    data = (data-data.mean())/data.std()\n",
    "    return data\n",
    "\n",
    "\n",
    "# 对菜品订单表售价和销量做标准化\n",
    "data4 = StandardScaler(detail['counts'])\n",
    "data5 = StandardScaler(detail['amounts'])\n",
    "data6 = pd.concat([data4, data5], axis=1)\n",
    "print('标准差标准化之前销量和售价数据为：\\n',\n",
    "      detail[['counts', 'amounts']].head())\n",
    "print('标准差标准化之后销量和售价数据为：\\n', data6.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
